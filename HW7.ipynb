{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YMIV5UkfDgJX",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install libraries\n",
    "!pip install datasets\n",
    "!pip install transformers\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DPizFHvcjDbj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# wandb - Create account on and log in to https://wandb.ai/, then paste the access token\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GxC-j6ezD-Pc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, TrainingArguments, Trainer\n",
    "import torch\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YRWZPf0eriBd"
   },
   "outputs": [],
   "source": [
    "# Load moral_stories dataset from Hugging Face - https://huggingface.co/datasets/demelin/moral_stories\n",
    "dataset=load_dataset('demelin/moral_stories','full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DJOlmDx6FgdF"
   },
   "outputs": [],
   "source": [
    "X_train = dataset['train']['norm'][:8000]\n",
    "X_test = dataset['train']['norm'][-2000:]\n",
    "print(\"Total Dataset (Including Validation) - \", len(dataset['train']))\n",
    "print(\"Train Dataset - \",len(X_train),'\\n',\"Test Dataset - \",len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xGCeIcwMmJS7"
   },
   "source": [
    "# Create GPT-2 tokenizer and define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f9mNrpLmsE0Q"
   },
   "outputs": [],
   "source": [
    "# Refer to Hugging Face documentation on Transformers https://huggingface.co/docs/transformers/v4.21.2/\n",
    "'''<<Insert tokenizer, model and resize token embedding code here>>'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aongHStfnxH6"
   },
   "source": [
    "# Tokenize data and split dataset into training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5s4SbSvcrM9h"
   },
   "outputs": [],
   "source": [
    "max_length = max([len(tokenizer.encode(x)) for x in X_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z_V2C1e3q42D"
   },
   "outputs": [],
   "source": [
    "class moral():\n",
    "    def __init__(self, x, tokenizer, max_length):\n",
    "        self.input_ids = []\n",
    "        self.attn_masks = []\n",
    "        self.labels = []\n",
    "        for txt in x:\n",
    "            encodings_dict = '''<<Insert tokenizer code and keep max_length as defined in above cell>>'''\n",
    "            self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
    "            self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.attn_masks[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SohdfTumrvS5"
   },
   "outputs": [],
   "source": [
    "# Split data 80-20 to form training and validation data\n",
    "dataset = moral(X_train, tokenizer, max_length=max_length)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, len(dataset) - train_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_z0KuJFDoFdd"
   },
   "source": [
    "# Define training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wYQPvQbzoOrB"
   },
   "outputs": [],
   "source": [
    "# Refer to wandb documentation to log training https://docs.wandb.ai/guides/integrations/huggingface\n",
    "training_args='''<<Insert code here for training arguments and experiment with the hyperparameters mentioned in the read me. Leave the rest to their default values.>>'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oDrf5Hu6t1ZG"
   },
   "outputs": [],
   "source": [
    "%env WANDB_WATCH=all\n",
    "%env WANDB_SILENT=true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MIuCNmpeoQJ1"
   },
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yzGEoXwjuKYN"
   },
   "outputs": [],
   "source": [
    "'''<<Insert code for trainer here>>'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L-rTbW0EtxzZ"
   },
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I-KFsT3KpPzO"
   },
   "source": [
    "# Inference using sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jjQIrNujF4z_"
   },
   "outputs": [],
   "source": [
    "'''<<Insert code for Tokenize sample data and use model.generate function to get predicted logits and decode them using tokenizer.decode function refer hugging face documentation for further information >>'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ie7ZPX_dpdwR"
   },
   "source": [
    "# Inference using test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HBeI5hjD5Igr"
   },
   "outputs": [],
   "source": [
    "'''<<Insert code for infering every sentence in test dataset X_test >>'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6srry5VhpxFe"
   },
   "source": [
    "# Evaluate model using BLEU score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m3pZgu-yLiA7"
   },
   "outputs": [],
   "source": [
    "# Compare predicted sentences from test data with actual test data. Refer to NLTK documentation for sentence_bleu\n",
    "import statistics\n",
    "from nltk.translate.bleu_score import sentence_bleu"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
